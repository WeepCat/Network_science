{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfdb5693-6b7c-4173-bb2f-e4f3a6e3cbc0",
   "metadata": {},
   "source": [
    "下面我们介绍一下 GraphSAGE 的代码实现，使用的是 DGL 框架。我们用 link prediction 作为模型的任务来举例。我们先简单的介绍一下链接预测这个任务。许多应用，如社交推荐、项目推荐、知识图谱补全等，都可以表述为链接预测，即预测两个特定节点之间是否存在边。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d49037ba-5857-42fd-a01c-596bacf681b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相关的库\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fadaac33-9390-4292-a154-352a3f3ac3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ./data/cora_v2.zip from https://data.dgl.ai/dataset/cora_v2.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./data/cora_v2.zip: 100%|████████████████████████████████████████████████████████████| 132k/132k [00:00<00:00, 404kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting file to ./data/cora_v2_d697a464\n",
      "Finished data loading and preprocessing.\n",
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done saving data into cached files.\n"
     ]
    }
   ],
   "source": [
    "# 导入Cora数据集\n",
    "import dgl.data\n",
    "\n",
    "dataset = dgl.data.CoraGraphDataset(raw_dir='./data/')\n",
    "g = dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad296555-dd9f-4a2d-8bed-0083b2b7277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备training set 和 testing set\n",
    "u, v = g.edges()\n",
    "\n",
    "eids = np.arange(g.number_of_edges())\n",
    "eids = np.random.permutation(eids)\n",
    "test_size = int(len(eids) * 0.1)\n",
    "train_size = g.number_of_edges() - test_size\n",
    "# 构造正样本\n",
    "test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
    "train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
    "\n",
    "# 构造负样本\n",
    "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))\n",
    "adj_neg = 1 - adj.todense() - np.eye(g.number_of_nodes())\n",
    "neg_u, neg_v = np.where(adj_neg != 0)\n",
    "\n",
    "neg_eids = np.random.choice(len(neg_u), g.number_of_edges())\n",
    "test_neg_u, test_neg_v = neg_u[neg_eids[:test_size]], neg_v[neg_eids[:test_size]]\n",
    "train_neg_u, train_neg_v = neg_u[neg_eids[test_size:]], neg_v[neg_eids[test_size:]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0794d62c-f300-4c9d-af7d-7aeaec6c96a3",
   "metadata": {},
   "source": [
    "训练时，您需要从原始图中删除测试集中的边。您可以通过 dgl.remove_edges 来完成此操作。dgl.remove_edges 的工作原理是从原始图创建子图，从而生成副本，因此对于大型图来说可能会很慢。如果是这样，您可以将训练和测试图保存到磁盘，就像预处理一样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4935c2b8-6167-4984-a450-ac0254fdf132",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_g = dgl.remove_edges(g, eids[:test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9000e7be-ee6f-44ef-890f-1838108ef24a",
   "metadata": {},
   "source": [
    "下面我们正式定义一个GraphSAGE模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7e458b2-010c-4859-b7a6-44a2a48ee189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import SAGEConv\n",
    "\n",
    "# 构建一个两层的 GraphSAGE 模型\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
    "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fb2314-40a2-4be5-a995-b6a4bd7d8152",
   "metadata": {},
   "source": [
    "然后，该模型通过计算两个节点的表示之间的得分来预测边缘存在的概率，通常通过一层MLP或者直接计算点积。\n",
    "\n",
    "DGL recommends you to treat the pairs of nodes as another graph, since you can describe a pair of nodes with an edge. In link prediction, you will have a positive graph consisting of all the positive examples as edges, and a negative graph consisting of all the negative examples. The positive graph and the negative graph will contain the same set of nodes as the original graph. This makes it easier to pass node features among multiple graphs for computation. As you will see later, you can directly feed the node representations computed on the entire graph to the positive and the negative graphs for computing pair-wise scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8edf0a7-c38e-405a-b97b-286797d3e07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建正样本和负样本的图\n",
    "train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.number_of_nodes())\n",
    "train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.number_of_nodes())\n",
    "\n",
    "test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.number_of_nodes())\n",
    "test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.number_of_nodes())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606f0f47-5e55-411a-86ac-7c279f63face",
   "metadata": {},
   "source": [
    "构建上面提到的预测函数，如点积和MLP，即 DotPredictor 和 MLPPredictor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "610d5927-22c7-48c9-b95b-8ad3050b718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.function as fn\n",
    "\n",
    "class DotPredictor(nn.Module):\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            # 通过点积计算一个新的边的分数\n",
    "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
    "            # u_dot_v 返回了一个 1-element 的向量，所以需要压平它\n",
    "            return g.edata['score'][:, 0]\n",
    "\n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, h_feats):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(h_feats * 2, h_feats)\n",
    "        self.W2 = nn.Linear(h_feats, 1)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        \"\"\"\n",
    "        Computes a scalar score for each edge of the given graph.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        edges :\n",
    "            Has three members ``src``, ``dst`` and ``data``, each of\n",
    "            which is a dictionary representing the features of the\n",
    "            source nodes, the destination nodes, and the edges\n",
    "            themselves.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary of new edge features.\n",
    "        \"\"\"\n",
    "        h = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
    "        return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(self.apply_edges)\n",
    "            return g.edata['score']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240facae-7bd3-4809-8f32-08c71b7b357d",
   "metadata": {},
   "source": [
    "下面展示整个任务的训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9d765948-b808-4390-8963-16a3bf98b303",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphSAGE(train_g.ndata['feat'].shape[1], 16)\n",
    "# You can replace DotPredictor with MLPPredictor.\n",
    "# pred = MLPPredictor(16)\n",
    "pred = DotPredictor()\n",
    "\n",
    "def compute_loss(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
    "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    return roc_auc_score(labels, scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "48a5d9a2-4dee-44f6-8b35-6c07c2892251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 0.7080111503601074\n",
      "In epoch 5, loss: 0.68918377161026\n",
      "In epoch 10, loss: 0.6679327487945557\n",
      "In epoch 15, loss: 0.6114687919616699\n",
      "In epoch 20, loss: 0.5494130849838257\n",
      "In epoch 25, loss: 0.5187898874282837\n",
      "In epoch 30, loss: 0.4887141287326813\n",
      "In epoch 35, loss: 0.4626503586769104\n",
      "In epoch 40, loss: 0.43711423873901367\n",
      "In epoch 45, loss: 0.41953739523887634\n",
      "In epoch 50, loss: 0.40007540583610535\n",
      "In epoch 55, loss: 0.3816624879837036\n",
      "In epoch 60, loss: 0.3635600209236145\n",
      "In epoch 65, loss: 0.345358282327652\n",
      "In epoch 70, loss: 0.32713955640792847\n",
      "In epoch 75, loss: 0.3090570867061615\n",
      "In epoch 80, loss: 0.29081523418426514\n",
      "In epoch 85, loss: 0.27249887585639954\n",
      "In epoch 90, loss: 0.25416550040245056\n",
      "In epoch 95, loss: 0.23578102886676788\n",
      "AUC 0.8646912692886504\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.01)\n",
    "\n",
    "# 训练\n",
    "all_logits = []\n",
    "for e in range(100):\n",
    "    # 前向传播\n",
    "    # 利用GraphSAGE作特征学习\n",
    "    h = model(train_g, train_g.ndata['feat'])\n",
    "    pos_score = pred(train_pos_g, h)\n",
    "    neg_score = pred(train_neg_g, h)\n",
    "    loss = compute_loss(pos_score, neg_score)\n",
    "\n",
    "    # 更新参数\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if e % 5 == 0:\n",
    "        print('In epoch {}, loss: {}'.format(e, loss))\n",
    "\n",
    "# 计算AUC\n",
    "with torch.no_grad():\n",
    "    pos_score = pred(test_pos_g, h)\n",
    "    neg_score = pred(test_neg_g, h)\n",
    "    print('AUC', compute_auc(pos_score, neg_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4dfb75-fb55-4c94-90bf-b9b3878341fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b444df0-a81d-4a3f-9664-c0491858e6d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
